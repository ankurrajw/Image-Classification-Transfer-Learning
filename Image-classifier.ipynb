{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIjzQnwvwLBE"
   },
   "source": [
    "# Image Classifier using Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using colab or other online clould services. add the location of drive where dataset has been stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4782,
     "status": "ok",
     "timestamp": 1612338830187,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "RDYszwllv_dX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import copy\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DytQ6g3OIXP"
   },
   "source": [
    "## Define Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2117,
     "status": "ok",
     "timestamp": 1612338830188,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "CLlZZTrN0HaY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        numfts = self.model.fc.in_features\n",
    "        #----------RESNET - 50\n",
    "        #self.model.fc = nn.Sequential(nn.Linear(self.model_in_fetures,1000),nn.ReLU(),nn.Dropout(0.5),\n",
    "        #      nn.Linear(1000,250),nn.ReLU(),nn.Dropout(0.5),\n",
    "        #      nn.Linear(250,50),nn.ReLU(),nn.Dropout(0.5),\n",
    "        #      nn.Linear(50,8))\n",
    "        self.model.fc = nn.Linear(numfts,8)\n",
    "        #----------RESNET - 18\n",
    "        #self.model.fc = nn.Sequential(nn.Linear(numfts,250),nn.ReLU(),nn.Dropout(0.5),\n",
    "        #                              nn.Linear(250,100),nn.ReLU(),nn.Dropout(0.5),\n",
    "        #                              nn.Linear(100,50),nn.ReLU(),nn.Dropout(0.5),\n",
    "        #                              nn.Linear(50,8))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return  F.log_softmax(self.model(x),dim = 1)\n",
    "        \n",
    "    \n",
    "    def save_model(self):\n",
    "        \n",
    "        torch.save(self.state_dict(), 'model_save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y79Y---lOLUJ"
   },
   "source": [
    "## Tansformation used for Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13457,
     "status": "ok",
     "timestamp": 1612338850270,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "5P8ypMmuwVmV"
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.RandomRotation(25),\n",
    "                              transforms.RandomResizedCrop(224),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "transNoAugment = transforms.Compose([transforms.Resize(255), \n",
    "                                  transforms.CenterCrop(224),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "class MyLazyDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            x = self.transform(dataset[index][0])\n",
    "        else:\n",
    "            x = dataset[index][0]\n",
    "        y = dataset[index][1]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(dataset)\n",
    "    \n",
    "# Load entire dataset once\n",
    "data_dir = '----add---location----'\n",
    "dataset = datasets.ImageFolder(data_dir)\n",
    "\n",
    "traindataset = MyLazyDataset(dataset,trans)\n",
    "valdataset = MyLazyDataset(dataset,transNoAugment)\n",
    "testdataset = MyLazyDataset(dataset,transNoAugment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split as well as Data Loders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1612338855221,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "dRWuOymAhmqa"
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "num_train = len(traindataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(train_size * num_train))\n",
    "split2 = int(np.floor((train_size+(1-train_size)/2) * num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_idx, valid_idx, test_idx = indices[:split], indices[split:split2], indices[split2:]\n",
    "\n",
    "traindata = Subset(traindataset, indices=train_idx)\n",
    "valdata = Subset(valdataset, indices=valid_idx)\n",
    "testdata = Subset(testdataset, indices=test_idx)\n",
    "\n",
    "num_workers = 5\n",
    "batch_size = 8\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainLoader = torch.utils.data.DataLoader(traindata, batch_size=batch_size, \n",
    "                                              num_workers=num_workers, drop_last=True)\n",
    "    valLoader = torch.utils.data.DataLoader(valdata, batch_size=batch_size, \n",
    "                                            num_workers=num_workers, drop_last=True)\n",
    "    testLoader = torch.utils.data.DataLoader(testdata, batch_size=batch_size,\n",
    "                                             num_workers=num_workers, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "executionInfo": {
     "elapsed": 17019,
     "status": "ok",
     "timestamp": 1612338877668,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "qcAqn-2WyRYD",
    "outputId": "789b03a1-11cc-46f4-cddf-dba0c21ed864"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(trainLoader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wjc5LUK8bEf"
   },
   "source": [
    "### Send Network to GPU(if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6U0p48ZOybzf"
   },
   "outputs": [],
   "source": [
    "net = Network()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEZ7kalj8fdO"
   },
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1612338915496,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "eMmO_KCA0a_4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLLeR0SBORlv"
   },
   "source": [
    "### Function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1612338920232,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "PsUikeBN1CZX"
   },
   "outputs": [],
   "source": [
    "def train_model(model,numEpoch,criterion,optimizer,scheduler):\n",
    "    since = time.time()\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(numEpoch):  # loop over the dataset multiple times\n",
    "        #valcount = 0\n",
    "        running_loss = 0.0\n",
    "        train_total = 0.0\n",
    "        train_correct = 0.0\n",
    "        for data in trainLoader:\n",
    "            model.train()\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device),data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_correct += torch.sum(predicted == labels.data)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            scheduler.step()\n",
    "            # print statistics\n",
    "            epoch_acc_train = 100 * train_correct / train_total\n",
    "            epoch_loss = running_loss/train_total\n",
    "            print(\"train total [%d] \" %(train_total))\n",
    "            print('[%d] epoch loss : %.3f' %(epoch + 1,epoch_loss))\n",
    "            print('[%d] train accuracy: %.3f' %(epoch + 1,epoch_acc_train))\n",
    "\n",
    "      #####Validation Step\n",
    "        val_correct = 0.0\n",
    "        val_total = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data in valLoader:\n",
    "                images, labels = data[0].to(device),data[1].to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_acc_val = 100 * val_correct / val_total\n",
    "        print(\"val total [%d] \" %(val_total))\n",
    "        print('[%d] val accuracy: %.3f' %(epoch + 1,epoch_acc_val))\n",
    "        if(epoch_acc_val > best_acc):\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            print('[%d] Increased Epoch Accuracy: %.3f' %\n",
    "                    (epoch + 1, epoch_acc_val))\n",
    "            best_acc = epoch_acc_val\n",
    "\n",
    "        #if(currentValAccuracy > prevValidationAccuracy):\n",
    "        #  print(\"Current Validation is more than previous for {0} pass : {1}\".format(valcount+1,currentValAccuracy))\n",
    "        #  valcount += 1\n",
    "        #  if(valcount > 3):\n",
    "        #    break\n",
    "\n",
    "    endtime = time.time()\n",
    "    print('Time Elapsed in mins - {0}'.format((endtime-since)/60))\n",
    "    print('Finished Training')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4367841,
     "status": "ok",
     "timestamp": 1612310924594,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "9LVFxad91TC_",
    "outputId": "9f431fde-112d-4e11-a905-6e303dfd0609"
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "trained_model = train_model(net,epoch,criterion,optimizer,exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXE8f6BJOX-g"
   },
   "source": [
    "### Saving Model and Load preious model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1621,
     "status": "ok",
     "timestamp": 1612339438016,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "_oRCUhUt11tf"
   },
   "outputs": [],
   "source": [
    "#torch.save(trained_model,'model100_epoch_resnet18_1linear')\n",
    "trained_model = torch.load('model100_epoch_resnet18_1linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5420,
     "status": "ok",
     "timestamp": 1612339562041,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "yaBHFcBkcDbt",
    "outputId": "0afe5a3d-f167-4bfa-db80-536bf578ed6c"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  trained_model.eval()\n",
    "  for data in testLoader:\n",
    "      images, labels = data[0].to(device),data[1].to(device)\n",
    "      outputs = trained_model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on test dataset is : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZzY6W9V_lWm"
   },
   "source": [
    "### Storing and saving result in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 110988,
     "status": "ok",
     "timestamp": 1612341337026,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "8ucR1aGH_y8F"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#net = model.Network().to(device)\n",
    "#net.load_state_dict(torch.load('model'))\n",
    "net = trained_model\n",
    "\n",
    "net.eval()\n",
    "filelist = glob.glob('----File_Location---/*.png')\n",
    "loader = transforms.Compose([transforms.Resize(224),transforms.ToTensor()])\n",
    "prediction = torch.tensor([],dtype = torch.float).to(device)\n",
    "i = 0\n",
    "label = []\n",
    "\n",
    "for fname in filelist:\n",
    "    image = Image.open(fname).convert('RGB')\n",
    "    image = loader(image).to(device)\n",
    "    \n",
    "    image = Variable(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    pred_image = net(image)\n",
    "    result_image = pred_image.argmax(dim = 1)\n",
    "        \n",
    "    prediction = torch.cat((prediction,result_image),dim = 0)\n",
    "    prediction = prediction.int()\n",
    "    fname2 = re.findall(r'\\d+',fname)\n",
    "    fname2 = list(map(int,fname2))\n",
    "    label.append(fname2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1612341499329,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "HMonBrJ5BGbQ"
   },
   "outputs": [],
   "source": [
    "#print(predten.argmax(dim = 1))\n",
    "class_names_predicted  = []\n",
    "prediction = prediction.to('cpu').numpy()\n",
    "class_names = dataset.classes\n",
    "label1 = label\n",
    "for i in prediction:\n",
    "    class_names_predicted.append(class_names[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1612341503591,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "eooqmMNyHyPi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_val = pd.DataFrame({'Id':label1,'Category':prediction,'Predicted class Label':class_names_predicted})\n",
    "data_val = data_val.sort_values('Id')\n",
    "data_val.to_csv('test2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1612341505126,
     "user": {
      "displayName": "ankur raj",
      "photoUrl": "",
      "userId": "06257443849547841919"
     },
     "user_tz": -60
    },
    "id": "yqF4kKrSN236",
    "outputId": "6d1d7fd8-e38f-46de-d363-6c3be019e817"
   },
   "outputs": [],
   "source": [
    "data_val"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNo8r5fcIQU3yj2Mz9Xs5kB",
   "collapsed_sections": [],
   "name": "Christmas Challenge 2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
